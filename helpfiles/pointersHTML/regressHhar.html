<!DOCTYPE HTML> <html itemscope="" xmlns="http://www.w3.org/1999/xhtml"> <head> <title>regressHhar</title> <meta content="refpage" name="chunktype"><meta content="function:regressHhar " itemprop="refentity" name="refentity"><meta content="fcn" itemprop="pagetype" name="toctype"><meta content="ref/function" itemprop="infotype" name="infotype" /><meta content="regressHhar RegressH fits a multiple linear regression model with Harvey heteroskedasticity" itemprop="description" name="description" /><script type="text/javascript"><!--   function Redirect() {      window.location= "matlab:web([docrootFS '/FSDA/regressHhar.html'])";   }   setTimeout('Redirect()', 10);//--></script></head><p style="background-color:#A9CCE3 "><em>Syllabus page indexed by builddocsearchdb for function: regressHhar</em></p><h1 itemprop="title">regressHhar</h1><h1 class="reftitle">regressHhar RegressH fits a multiple linear regression model with Harvey heteroskedasticity</h1><h2>Description</h2><P></P><h2>More About</h2><P>
   This routine implements Harvey’s (1976) model of
   multiplicative heteroscedasticity which is a very flexible, general
   model that includes most of the useful formulations as special cases.
   The general formulation is: 
   
       $\sigma^2_i =\sigma^2 \exp(z_i \alpha)$
   
   Let $z_i$ include a constant term so that \( z_i'=(1 \; q_i) \) where \( q_i \) is the
   original set of variables which are supposed to explain
   heteroscedasticity. This routine automatically adds a column of 1 to
   input matrix Z (therefore Z does not have to include a constant term).
   Now let 
   \[  
   \gamma'=[\log \sigma^2 \alpha'] = [ \gamma_0, \ldots, \gamma_r]. 
   \] 
   Then the model is simply
   \[
   \sigma^2_i = \exp(\gamma' z_i)
   \]
   Once the full parameter vector is estimated \( \exp( \gamma_0)\) provides the
   estimator for \( \sigma^2 \). 

  The model is:  
               \[
                 y=X \times\beta+ \epsilon,  \qquad 
                 \epsilon \sim N(0, \;  \Sigma)
               \]
               \[
                   \Sigma=diag(\sigma_1^2, ..., \sigma_n^2)    \qquad
                   \sigma_i^2=\exp(z_i^T \times \gamma)        \qquad
                   var(\epsilon_i)=\sigma_i^2                  \qquad
                   i=1, ..., n    
               \]                                                      
               $\beta$ = p-by-1 vector which contains regression
               parameters.                                                 
               $\gamma$ = (r+1)-times-1 vector $\gamma_0, \ldots,
               \gamma_r$ (or written in MATLAB language $(\gamma(1),
               \ldots, \gamma(r+1))$) which contains skedastic parameters.
               $X$ = n-by-p matrix containing explanatory variables in the
               mean equation (including the constant term if present).
               $Z$ = n-by-(r+1) matrix containing the explanatory
               variables in the skedastic equation. $Z= (z_1^T, \ldots,
               z_n^T)^T$ 
               $z_i^T=(1, z_{i,1}, \ldots, z_{i,r})$ (or written in MATLAB
               language  $z_i=(z(1), \ldots, z(r+1)$).
               REMARK1: given that the first element of $z_i$ is equal to 1
               $\sigma_i^2$ can be written as
               \[
               \sigma_i^2 = \sigma^2 \times \exp(z_i(2:r+1)*\gamma(2:r+1))
                          = \exp(\gamma(1))*\exp(z_i(2:r+1)*\gamma(2:r+1))
               \]
               that is, once the full parameter vector $\gamma$ containing
               the skedastic parameters is estimated $\exp( \gamma(1))$
               provides the estimator for $\sigma^2$. 
               REMARK2: if $Z=log(X)$ then
               \[
                            \sigma^2_i= \exp(z_i^T \times \gamma) =
                           \prod_{j=1}^p x_{ij}^{\gamma_j}     \qquad  
                            j=1, ..., p
               \]
               REMARK3: if there is just one explanatory variable (say $x
               =(x_1 \ldots, x_n)$) which is responsible for
               heteroskedasticity and the model is
               \[
               \sigma^2_i=( \sigma^2 \times x_i^\alpha)
               \]
               then it is necessary to supply $Z$ as $Z=log(x)$. In this
               case, given that the program automatically adds a column of
               ones to $Z$
               \[
                  \exp(Z(i,1) \times \gamma(1) +Z(i,2) \times \gamma(2))=
                  \exp(\gamma(1))*x_i^{\gamma(2)}
               \]
               therefore the $\exp$ of the first element of vector
               $\gamma$ (namely exp(gamma(1))) is the estimate of
               $\sigma^2$ while the second element of vector $\gamma$
               (namely gamma(2)) is the estimate of $\alpha$


</P><h2>References</h2><P>Greene W.H.(1987), Econometric Analysis (5th edition, section 11.7.1
   pp. 232-235), (7th edition, section  9.7.1 pp. 280-282), Prentice Hall.</P></html>