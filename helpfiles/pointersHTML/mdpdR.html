<!DOCTYPE HTML> <html itemscope="" xmlns="http://www.w3.org/1999/xhtml"> <head> <title>mdpdR</title> <meta content="refpage" name="chunktype"><meta content="function:mdpdR " itemprop="refentity" name="refentity"><meta content="fcn" itemprop="pagetype" name="toctype"><meta content="ref/function" itemprop="infotype" name="infotype" /><meta content="mdpdR Allows to apply Minimum Density Power Divergence criterion to parametric regression problems" itemprop="description" name="description" /><h1 itemprop="title">mdpdR</h1><script type="text/javascript"><!--   function Redirect() {var l = document.getElementById('link');l.click();   }   setTimeout('Redirect()', 400);//--></script></head> <a href="matlab:web([docrootFS '/FSDA/mdpdR.html'])"; target="_top" id="link">Link to formatted HTML documentation in Mathworks style of '/FSDA/mdpdR.html'</a> <P>If redirecting does not work you can see the proper HTML documentation of this page in Mathworks style at the web address of the Robust Statistics Academy of the University of Parma (RoSA)<P> <a href="http://rosa.unipr.it/FSDA/mdpdR.html">http://rosa.unipr.it/FSDA/mdpdR.html</a></P><hr /><p style="background-color:#A9CCE3 "><em>Syllabus page indexed by builddocsearchdb for function: mdpdR</em></p><P>mdpdR</P><P>Allows to apply Minimum Density Power Divergence criterion to parametric regression problems</P><h2>More About</h2><P>

 We assume that the random variables $Y|x$ are distributed as normal $N(
 \eta(x,\beta), \sigma_0)$ random variable with density function $\phi$.
 Note that if the model is linear $\eta(x,\beta)= x^T \beta$. The estimate
 of the vector $\theta_\alpha=(\beta_1, \ldots, \beta_p)^T$  (Minimum
 Density Power Divergence Estimate) is given by:

 \[
  \mbox{argmin}_{\beta, \sigma} \left[ \frac{1}{\sigma^\alpha \sqrt{ (2
  \pi)^\alpha(1+\alpha)}}-\frac{\alpha+1}{\alpha} \frac{1}{n} \sum_{i=1}^n
  \phi^\alpha (y_i| \eta (x_i, \beta), \sigma)
  \right]
  \]

 As the tuning paramter $\alpha$ increases, the robustness of the Minimum
 Density Power Divergence Estimator (MDPDE) increases while its efficieny
 decreases (Basu et al. 1998). For $\alpha=0$ the MDPDE becomes the Maximum
 Likelihood Estimator, while for $\alpha=1$ the estimator minimizes the
 $L_2$ distance between the densities (Durio and Isaia, 2003),



</P><h2>References</h2><P>Basu, A., Harris, I.R., Hjort, N.L. and Jones, M.C., (1998), Robust and
   efficient estimation by minimizing a density power divergence,
   "Biometrika", Vol. 85, pp. 549-559.</P></html>